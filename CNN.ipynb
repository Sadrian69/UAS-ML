{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96a7315-43c1-4604-8fc4-a663cf9f834f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Laporan Project UAS Machine Learning\n",
    "\n",
    "Adi Christian C14210091\\\n",
    "Meike Surajiman C14210116\\\n",
    "Steven Adrian Gracia C14210171\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a7b788-8cc8-4a27-bd30-01365b57a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "aman\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "print(\"aman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64092b7a-4076-4c22-8a88-2a665f240f39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pengenalan dataset\n",
    "Dataset yang kami pakai adalah [MNIST](http://yann.lecun.com/exdb/mnist/) . Dataset ini berisi beberapa gambar angka yang ditulis tangan. Dataset ini memberikan kesempatan bagi algoritma machine learning untuk mengidentifikasi digit yang benar dari gambar-gambar tersebut. Dataset yang kami gunakan berasal langsung dari keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8590500e-b079-4ad4-9ba1-f1b5537cc836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facffc80-643f-4b87-985b-eb68263286dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "Ada beberapa hal yang perlu dilakukan sebelum memproses dataset tersebut, diantaranya:\n",
    "1. Normalisasi\n",
    "2. Reshape\n",
    "3. Label encoding\n",
    "4. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585228b-efbd-48f6-85cd-0e33a471505d",
   "metadata": {},
   "source": [
    "1. Data yang dimuat berada di range 0 sampai 255. Supaya CNN konvergen lebih cepat, bisa dilakukan normalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677ed96c-b818-40b1-9f75-bc0975899ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8986492e-3429-44e1-a4be-6d748dd185b6",
   "metadata": {},
   "source": [
    "2. Array X akan lebih mudah divisualisasi jika direshape sebagai \"gambar\" dengan height dan width 28px beserta grayscalenya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ef1c7a-eaf0-44a2-9b73-47e73db83cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((-1,28,28,1)).astype(\"float32\")\n",
    "test_images = test_images.reshape((-1,28,28,1)).astype(\"float32\")\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c314c5-4c43-41c1-a397-48429cda7b74",
   "metadata": {},
   "source": [
    "3. Karena y (label tiap gambar) tidak memiliki relasi ordinal, maka dilakukan one-hot encoding sehingga hasil dari CNN tidak terpengaruh selisih angka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1242fbf-2849-4c8d-8e04-28ac7be1ed46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23474624-0005-4450-92be-e6406da9d3ed",
   "metadata": {},
   "source": [
    "4. Split data untuk train dan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7e1e2e-1a51-42b6-96ad-909fdc2b73fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28, 1) (6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "print(train_images.shape, val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88f673-4870-4e6f-b1b3-639d9ff193d1",
   "metadata": {},
   "source": [
    "Contoh visualisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6e6584-1ce8-4cb2-8253-38c5ae30a863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = train_images.reshape(train_images.shape[0], 28, 28)\n",
    "\n",
    "fig, axis = plt.subplots(1, 5, figsize=(20, 10))\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    ax.imshow(temp[i], cmap='binary')\n",
    "    digit = train_labels[i].argmax()\n",
    "    ax.set(title = f\"Real Number is {digit}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843affb-6a75-486c-9752-481582b9a798",
   "metadata": {},
   "source": [
    "Untuk menghindari overfitting, dataset yang sudah ada diperluas dengan menggunakan data augmentation. Caranya adalah memberi sedikit variasi untuk setiap data dengan cara memperbesar/kecil, mengubah tempat, dll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f352eb-4ebf-4bfb-bdb8-5e495d73785e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False, \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=15,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False)  \n",
    "# akan digunakan saat fitting nanti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399aa2d5-c90e-4ca2-9bc0-c7d539fbd1c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metode CNN: AlexNet\n",
    "AlexNet adalah sebuah arsitektur CNN yang cukup simpel. Di sini akan diimplementasikan Alexnet dari awal menggunakan Keras Sequential API dengan cara menumpuk layer CNN satu sama lain.\n",
    "Ada beberapa jenis layer CNN di AlexNet:\n",
    "- Convolutional layer: sebuah perkalian dot product antara 2 elemen, berisi operasi convolutional antara filter dan image\n",
    "- Batch Normalisation layer: layer tambahan yang menstandarisasi dan menormalisasi nilai input\n",
    "- Max Pooling layer: mencari nilai max dari sebuah range sebagai output\n",
    "- Flatten layer: mengubah image menjadi array 1D\n",
    "- Dense layer: berisi banyak neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7af4cb-fdcd-4ba7-a3a2-e5a95332044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping untuk berhenti dahulu jika sudah fit\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=3, \n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a78fef4-a57d-4073-a603-57294e00554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 26, 26, 64)        256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 24, 24, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                368650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406730 (1.55 MB)\n",
      "Trainable params: 406474 (1.55 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab00126-ae61-408e-986c-9297369342d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "844/844 [==============================] - 37s 42ms/step - loss: 0.6024 - accuracy: 0.8886 - val_loss: 0.1982 - val_accuracy: 0.9512\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 33s 39ms/step - loss: 0.2008 - accuracy: 0.9503 - val_loss: 0.2702 - val_accuracy: 0.9302\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 31s 37ms/step - loss: 0.1443 - accuracy: 0.9620 - val_loss: 0.1067 - val_accuracy: 0.9725\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.1230 - accuracy: 0.9668 - val_loss: 0.1410 - val_accuracy: 0.9597\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 0.1054 - accuracy: 0.9709 - val_loss: 0.1107 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909c2d1f-9c90-4054-99a9-67ca0f20b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1114 - accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3fa055-be9b-4319-b926-a1098c3719bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 2.91%\n",
      "Test error: 2.84%\n",
      "Duration: 162.14 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9043c15b-8107-4163-a760-43ee05d12593",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append({\n",
    "    \"Configuration\": \"model\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ff5f7-9c43-47a8-81a3-de37ea1a68f1",
   "metadata": {},
   "source": [
    "## Konfigurasi parameter CNN\n",
    "Kami mencoba beberapa konfigurasi parameter di CNN. Diantaranya:\n",
    "- Batch Size\n",
    "- Kernel Initializer (HE/Glorot)\n",
    "- Jumlah hidden layer\n",
    "- Jumlah channels hidden layer\n",
    "- Kernel size hidden layer\n",
    "- Stride hidden layer\n",
    "- Activation function hidden layer\n",
    "- Jumlah neuron output layer\n",
    "- Activation function output layer\n",
    "- Regularization\n",
    "- Max pooling\n",
    "\n",
    "\n",
    "Data yang kami dapatkan sebagai berikut dengan implementasi di bawahnya\n",
    "| CONFIGURATION | LAYERS | REGULARIZATION | TRAIN ERROR | TEST ERROR | DURATION(seconds) |\n",
    "|---------------|--------|----------------|-------------|------------|----------|\n",
    "| Model         |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.91%|2.84%|162.14|\n",
    "| Conf1         |Batch=32, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.84%|2.76%|165.65|\n",
    "| Conf2         |Batch=128, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.98%|2.04%|149.57|\n",
    "| Conf3         |Batch=64, Epoch=3,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||3.94%|2.57%|89.35|\n",
    "| Conf4         |Batch=64, Epoch=10,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.02%|1.47%|295.96|\n",
    "| Conf5         |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,HE<br>C64x28x28,K=3,S=1,ReLu,HE<br>F10,softmax,cross-entropy loss||2.94%|2.27%|152.92|\n",
    "| Conf6         |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.60%|1.69%|242.43|\n",
    "| Conf7         |Batch=64, Epoch=5,<br>C32x28x28,K=3,S=1,ReLu,Glorot<br>C32x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.88%|1.78%|72.46|\n",
    "| Conf8         |Batch=64, Epoch=5,<br>C128x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||3.01%|2.21%|462.22|\n",
    "| Conf9         |Batch=64, Epoch=5,<br>C64x28x28,K=1,S=1,ReLu,Glorot<br>C64x28x28,K=1,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||23.27%|46.66%|115.73|\n",
    "| Conf10        |Batch=64, Epoch=5,<br>C64x28x28,K=5,S=1,ReLu,Glorot<br>C64x28x28,K=5,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.46%|1.20%|227.57|\n",
    "| Conf11        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||2.94%|2.38%|60.68|\n",
    "| Conf12        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=3,ReLu,Glorot<br>C64x28x28,K=3,S=3,ReLu,Glorot<br>F10,softmax,cross-entropy loss||4.45%|2.12%|52.04|\n",
    "| Conf13        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,Sigmoid,Glorot<br>C64x28x28,K=3,S=1,Sigmoid,Glorot<br>F10,softmax,cross-entropy loss||4.50%|3.37%|159.50|\n",
    "| Conf14        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,Tanh,Glorot<br>C64x28x28,K=3,S=1,Tanh,Glorot<br>F10,softmax,cross-entropy loss||5.19%|5.82%|123.64|\n",
    "| Conf15        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,Leaky ReLu,Glorot<br>C64x28x28,K=3,S=1,Leaky ReLu,Glorot<br>F10,softmax,cross-entropy loss||3.89%|3.26%|159.73|\n",
    "| Conf16        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,Linear,Glorot<br>C64x28x28,K=3,S=1,Linear,Glorot<br>F10,softmax,cross-entropy loss||34.42%|17.14%|141.16|\n",
    "| Conf17        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,Exponential,Glorot<br>C64x28x28,K=3,S=1,Exponential,Glorot<br>F10,softmax,cross-entropy loss||4.16%|8.24%|163.43|\n",
    "| Conf18        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F32,ReLu,F10,softmax,cross-entropy loss||2.59%|1.52%|172.46|\n",
    "| Conf19        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F64,ReLu,F10,softmax,cross-entropy loss||2.31%|1.41%|207.98|\n",
    "| Conf20        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F128,ReLu,F10,softmax,cross-entropy loss||2.46%|1.44%|264.65|\n",
    "| Conf21        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,sigmoid,cross-entropy loss||2.81%|2.36%|149.08|\n",
    "| Conf22        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,linear,cross-entropy loss||88.25%|84.28%|149.58|\n",
    "| Conf23        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss|Dropout=0.2|3.52%|1.29%|272.95|\n",
    "| Conf24        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>C64x28x28,K=3,S=1,ReLu,Glorot<br>F10,softmax,cross-entropy loss|Dropout=0.5|6.09%|1.26%|277.37|\n",
    "| Conf25        |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=1,ReLu,Glorot,MaxPool=2<br>C128x28x28,K=3,S=1,ReLu,Glorot,MaxPool=2<br>F10,softmax,cross-entropy loss||1.99%|1.42%|81.44|\n",
    "| Final         |Batch=32, Epoch=30,<br>C128x28x28,K=5,S=1,ReLu,He,MaxPool=2<br>C256x28x28,K=5,S=1,ReLu,He,MaxPool=2<br>C512x28x28,K=5,S=1,ReLu,He,MaxPool=2<br>F1024,ReLu,F10,softmax,cross-entropy loss|Dropout=0.2|0.93%|0.64%|1459.08|\n",
    "| Best          |Batch=32, Epoch=30,<br>C32x28x28,K=5,S=1,ReLu,He,MaxPool=2<br>C64x28x28,K=5,S=1,ReLu,He,MaxPool=2<br>C128x28x28,K=5,S=1,ReLu,He,MaxPool=2<br>F256,ReLu,F10,softmax,cross-entropy loss|Dropout=0.2|0.89%|0.60%|317.77|\n",
    "\n",
    "Dari data yang kami dapatkan, konfigurasi yang terbaik adalah Best dengan train error 0.89% dan test error 0.60%. Konfigurasi ini menggunakan beberapa layer hidden dan output dengan batch size yang kecil dan jumlah epoch yang banyak, meskipun terjadi early stop. Jumlah feature yang digunakan lebih sedikit karena MNIST bukanlah data yang kompleks sehingga dapat menghindari overfitting, dengan kernel yang cukup besar dan stride 1. Activation function yang digunakan adalah ReLu dan SoftMax yang memang cocok untuk masalah ini, dengan initialization HE untuk problem klasifikasi dibandingkan glorot. Di dalam model, dilakukan beberapa kali max pooling dan penambahan fitur setiap maxpool untuk memperbagus hasil, dan juga dilakukan reguralization dropout satu kali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e43b28-6004-4154-ae64-3f2b4d3be14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 33s 19ms/step - loss: 0.6199 - accuracy: 0.8925 - val_loss: 0.5378 - val_accuracy: 0.8925\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.1940 - accuracy: 0.9526 - val_loss: 0.1250 - val_accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.1391 - accuracy: 0.9632 - val_loss: 0.0928 - val_accuracy: 0.9723\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 36s 21ms/step - loss: 0.1086 - accuracy: 0.9684 - val_loss: 0.0918 - val_accuracy: 0.9718\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.0940 - accuracy: 0.9716 - val_loss: 0.0939 - val_accuracy: 0.9718\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0851 - accuracy: 0.9724\n",
      "Train error: 2.84%\n",
      "Test error: 2.76%\n",
      "Duration: 165.65 seconds\n"
     ]
    }
   ],
   "source": [
    "conf1=Sequential()\n",
    " \n",
    "conf1.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf1.add(BatchNormalization())\n",
    "conf1.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf1.add(BatchNormalization())\n",
    "    \n",
    "conf1.add(Flatten())\n",
    "conf1.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf1.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=32),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf1.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf1\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bebf2e90-032a-4124-87c1-6aa95ee073f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 32s 73ms/step - loss: 0.6664 - accuracy: 0.8774 - val_loss: 4.9699 - val_accuracy: 0.0975\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 30s 72ms/step - loss: 0.2374 - accuracy: 0.9461 - val_loss: 0.5460 - val_accuracy: 0.8593\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 29s 69ms/step - loss: 0.1604 - accuracy: 0.9612 - val_loss: 0.5122 - val_accuracy: 0.8692\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 29s 69ms/step - loss: 0.1283 - accuracy: 0.9677 - val_loss: 0.0988 - val_accuracy: 0.9748\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 29s 69ms/step - loss: 0.1133 - accuracy: 0.9702 - val_loss: 0.1117 - val_accuracy: 0.9760\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0785 - accuracy: 0.9796\n",
      "Train error: 2.98%\n",
      "Test error: 2.04%\n",
      "Duration: 149.57 seconds\n"
     ]
    }
   ],
   "source": [
    "conf2=Sequential()\n",
    " \n",
    "conf2.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf2.add(BatchNormalization())\n",
    "conf2.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf2.add(BatchNormalization())\n",
    "    \n",
    "conf2.add(Flatten())\n",
    "conf2.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf2.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=128),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf2.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf2\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba082e84-e55a-4c7e-aa35-763a3bc680a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.7542 - accuracy: 0.8820 - val_loss: 0.2487 - val_accuracy: 0.9502\n",
      "Epoch 2/3\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.2259 - accuracy: 0.9500 - val_loss: 0.1294 - val_accuracy: 0.9737\n",
      "Epoch 3/3\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.1612 - accuracy: 0.9606 - val_loss: 0.1207 - val_accuracy: 0.9703\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0955 - accuracy: 0.9743\n",
      "Train error: 3.94%\n",
      "Test error: 2.57%\n",
      "Duration: 89.35 seconds\n"
     ]
    }
   ],
   "source": [
    "conf3=Sequential()\n",
    " \n",
    "conf3.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf3.add(BatchNormalization())\n",
    "conf3.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf3.add(BatchNormalization())\n",
    "    \n",
    "conf3.add(Flatten())\n",
    "conf3.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf3.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=3,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf3.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf3\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e94a069c-78bb-4fe8-b50d-e1faa3911ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.6200 - accuracy: 0.8868 - val_loss: 0.1838 - val_accuracy: 0.9540\n",
      "Epoch 2/10\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.2089 - accuracy: 0.9491 - val_loss: 0.1256 - val_accuracy: 0.9692\n",
      "Epoch 3/10\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1517 - accuracy: 0.9623 - val_loss: 0.1117 - val_accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.1289 - accuracy: 0.9665 - val_loss: 0.0928 - val_accuracy: 0.9748\n",
      "Epoch 5/10\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.1061 - accuracy: 0.9711 - val_loss: 0.0787 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.0972 - accuracy: 0.9728 - val_loss: 0.0695 - val_accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.0797 - accuracy: 0.9764 - val_loss: 0.1170 - val_accuracy: 0.9727\n",
      "Epoch 8/10\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.0770 - accuracy: 0.9772 - val_loss: 0.0447 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.0683 - accuracy: 0.9795 - val_loss: 0.0651 - val_accuracy: 0.9813\n",
      "Epoch 10/10\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.0699 - accuracy: 0.9798 - val_loss: 0.0639 - val_accuracy: 0.9823\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0534 - accuracy: 0.9853\n",
      "Train error: 2.02%\n",
      "Test error: 1.47%\n",
      "Duration: 295.96 seconds\n"
     ]
    }
   ],
   "source": [
    "conf4=Sequential()\n",
    " \n",
    "conf4.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf4.add(BatchNormalization())\n",
    "conf4.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf4.add(BatchNormalization())\n",
    "    \n",
    "conf4.add(Flatten())\n",
    "conf4.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf4.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf4.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=10,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf4.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf4\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d71d022a-8248-43f3-a307-6b0031d81559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.7866 - accuracy: 0.8844 - val_loss: 0.2926 - val_accuracy: 0.9548\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.3035 - accuracy: 0.9484 - val_loss: 0.1913 - val_accuracy: 0.9655\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 0.1985 - accuracy: 0.9592 - val_loss: 0.1114 - val_accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 0.1497 - accuracy: 0.9661 - val_loss: 0.1265 - val_accuracy: 0.9708\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 0.1179 - accuracy: 0.9706 - val_loss: 0.0972 - val_accuracy: 0.9768\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0833 - accuracy: 0.9773\n",
      "Train error: 2.94%\n",
      "Test error: 2.27%\n",
      "Duration: 152.92 seconds\n"
     ]
    }
   ],
   "source": [
    "conf5=Sequential()\n",
    " \n",
    "conf5.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
    "conf5.add(BatchNormalization())\n",
    "conf5.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "conf5.add(BatchNormalization())\n",
    "    \n",
    "conf5.add(Flatten())\n",
    "conf5.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf5.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf5.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf5.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf5\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85173590-2e1e-409f-8a60-a6b5cf71486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 48s 56ms/step - loss: 0.7272 - accuracy: 0.8927 - val_loss: 0.2620 - val_accuracy: 0.9595\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 47s 56ms/step - loss: 0.3282 - accuracy: 0.9522 - val_loss: 0.2848 - val_accuracy: 0.9647\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 51s 60ms/step - loss: 0.2094 - accuracy: 0.9639 - val_loss: 0.1085 - val_accuracy: 0.9803\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 49s 58ms/step - loss: 0.1445 - accuracy: 0.9710 - val_loss: 0.1156 - val_accuracy: 0.9747\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 47s 56ms/step - loss: 0.1157 - accuracy: 0.9740 - val_loss: 0.0689 - val_accuracy: 0.9838\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0687 - accuracy: 0.9831\n",
      "Train error: 2.60%\n",
      "Test error: 1.69%\n",
      "Duration: 242.43 seconds\n"
     ]
    }
   ],
   "source": [
    "conf6=Sequential()\n",
    " \n",
    "conf6.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf6.add(BatchNormalization())\n",
    "conf6.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf6.add(BatchNormalization())\n",
    "conf6.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf6.add(BatchNormalization())\n",
    "    \n",
    "conf6.add(Flatten())\n",
    "conf6.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf6.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf6.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf6.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf6\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e89aea7-76cc-4b7b-b924-39e71a157f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 15s 17ms/step - loss: 0.4641 - accuracy: 0.8897 - val_loss: 0.1287 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 14s 17ms/step - loss: 0.2057 - accuracy: 0.9476 - val_loss: 0.2734 - val_accuracy: 0.9167\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 14s 17ms/step - loss: 0.1462 - accuracy: 0.9599 - val_loss: 0.1466 - val_accuracy: 0.9650\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 14s 17ms/step - loss: 0.1161 - accuracy: 0.9673 - val_loss: 0.0912 - val_accuracy: 0.9717\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 14s 17ms/step - loss: 0.1010 - accuracy: 0.9712 - val_loss: 0.0661 - val_accuracy: 0.9812\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.9822\n",
      "Train error: 2.88%\n",
      "Test error: 1.78%\n",
      "Duration: 72.46 seconds\n"
     ]
    }
   ],
   "source": [
    "conf7=Sequential()\n",
    " \n",
    "conf7.add(Conv2D(filters=32, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf7.add(BatchNormalization())\n",
    "conf7.add(Conv2D(filters=32, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf7.add(BatchNormalization())\n",
    "    \n",
    "conf7.add(Flatten())\n",
    "conf7.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf7.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf7.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf7.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf7\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95062a10-d7b7-4bc4-81af-334b2a3d7909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 93s 110ms/step - loss: 1.0919 - accuracy: 0.8794 - val_loss: 0.7839 - val_accuracy: 0.8387\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 92s 109ms/step - loss: 0.2203 - accuracy: 0.9487 - val_loss: 0.1800 - val_accuracy: 0.9585\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 93s 110ms/step - loss: 0.1594 - accuracy: 0.9602 - val_loss: 0.1198 - val_accuracy: 0.9730\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 92s 109ms/step - loss: 0.1270 - accuracy: 0.9664 - val_loss: 0.1425 - val_accuracy: 0.9677\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 92s 109ms/step - loss: 0.1105 - accuracy: 0.9699 - val_loss: 0.0969 - val_accuracy: 0.9772\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0941 - accuracy: 0.9779\n",
      "Train error: 3.01%\n",
      "Test error: 2.21%\n",
      "Duration: 462.22 seconds\n"
     ]
    }
   ],
   "source": [
    "conf8=Sequential()\n",
    " \n",
    "conf8.add(Conv2D(filters=128, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf8.add(BatchNormalization())\n",
    "conf8.add(Conv2D(filters=128, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf8.add(BatchNormalization())\n",
    "    \n",
    "conf8.add(Flatten())\n",
    "conf8.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf8.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf8.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf8.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf8\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a29fce52-a598-401e-b862-a7bd53cf930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 23s 26ms/step - loss: 1.2110 - accuracy: 0.6591 - val_loss: 4.2552 - val_accuracy: 0.1435\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 23s 27ms/step - loss: 0.8874 - accuracy: 0.7271 - val_loss: 2.7222 - val_accuracy: 0.3842\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 23s 27ms/step - loss: 0.8312 - accuracy: 0.7480 - val_loss: 1.2527 - val_accuracy: 0.6245\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 23s 28ms/step - loss: 0.7864 - accuracy: 0.7603 - val_loss: 1.1585 - val_accuracy: 0.6435\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 24s 28ms/step - loss: 0.7685 - accuracy: 0.7673 - val_loss: 1.6613 - val_accuracy: 0.5380\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.6629 - accuracy: 0.5334\n",
      "Train error: 23.27%\n",
      "Test error: 46.66%\n",
      "Duration: 115.73 seconds\n"
     ]
    }
   ],
   "source": [
    "conf9=Sequential()\n",
    " \n",
    "conf9.add(Conv2D(filters=64, kernel_size = (1,1), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf9.add(BatchNormalization())\n",
    "conf9.add(Conv2D(filters=64, kernel_size = (1,1), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf9.add(BatchNormalization())\n",
    "    \n",
    "conf9.add(Flatten())\n",
    "conf9.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf9.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf9.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf9.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf9\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c35731bf-6c0e-401d-94d0-5230cf5135a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 46s 54ms/step - loss: 0.5463 - accuracy: 0.9064 - val_loss: 0.6315 - val_accuracy: 0.8905\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 46s 54ms/step - loss: 0.2340 - accuracy: 0.9584 - val_loss: 0.1945 - val_accuracy: 0.9693\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 46s 54ms/step - loss: 0.1720 - accuracy: 0.9653 - val_loss: 0.1077 - val_accuracy: 0.9763\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 45s 53ms/step - loss: 0.1243 - accuracy: 0.9729 - val_loss: 0.1138 - val_accuracy: 0.9782\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 45s 53ms/step - loss: 0.1137 - accuracy: 0.9754 - val_loss: 0.0564 - val_accuracy: 0.9882\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0465 - accuracy: 0.9880\n",
      "Train error: 2.46%\n",
      "Test error: 1.20%\n",
      "Duration: 227.57 seconds\n"
     ]
    }
   ],
   "source": [
    "conf10=Sequential()\n",
    " \n",
    "conf10.add(Conv2D(filters=64, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf10.add(BatchNormalization())\n",
    "conf10.add(Conv2D(filters=64, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf10.add(BatchNormalization())\n",
    "    \n",
    "conf10.add(Flatten())\n",
    "conf10.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf10.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf10.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf10.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf10\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a07c0b26-cc68-418f-898c-d72f41c719e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 14s 15ms/step - loss: 0.3421 - accuracy: 0.8928 - val_loss: 0.1137 - val_accuracy: 0.9628\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 12s 14ms/step - loss: 0.1542 - accuracy: 0.9533 - val_loss: 0.0856 - val_accuracy: 0.9737\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 12s 14ms/step - loss: 0.1236 - accuracy: 0.9617 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 12s 14ms/step - loss: 0.1086 - accuracy: 0.9667 - val_loss: 0.0758 - val_accuracy: 0.9775\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 12s 14ms/step - loss: 0.0962 - accuracy: 0.9706 - val_loss: 0.0877 - val_accuracy: 0.9757\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9762\n",
      "Train error: 2.94%\n",
      "Test error: 2.38%\n",
      "Duration: 60.68 seconds\n"
     ]
    }
   ],
   "source": [
    "conf11=Sequential()\n",
    " \n",
    "conf11.add(Conv2D(filters=64, kernel_size = (3,3), strides=(2,2), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf11.add(BatchNormalization())\n",
    "conf11.add(Conv2D(filters=64, kernel_size = (3,3), strides=(2,2), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf11.add(BatchNormalization())\n",
    "    \n",
    "conf11.add(Flatten())\n",
    "conf11.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf11.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf11.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf11.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf11\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6972813-1283-421e-b9f4-a1c0caea0c71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 11s 12ms/step - loss: 0.4915 - accuracy: 0.8489 - val_loss: 0.1510 - val_accuracy: 0.9607\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.2173 - accuracy: 0.9339 - val_loss: 0.1064 - val_accuracy: 0.9680\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.1810 - accuracy: 0.9438 - val_loss: 0.0992 - val_accuracy: 0.9698\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.1576 - accuracy: 0.9518 - val_loss: 0.1015 - val_accuracy: 0.9675\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.1452 - accuracy: 0.9555 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9788\n",
      "Train error: 4.45%\n",
      "Test error: 2.12%\n",
      "Duration: 52.04 seconds\n"
     ]
    }
   ],
   "source": [
    "conf12=Sequential()\n",
    " \n",
    "conf12.add(Conv2D(filters=64, kernel_size = (3,3), strides=(3,3), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf12.add(BatchNormalization())\n",
    "conf12.add(Conv2D(filters=64, kernel_size = (3,3), strides=(3,3), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf12.add(BatchNormalization())\n",
    "    \n",
    "conf12.add(Flatten())\n",
    "conf12.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf12.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf12.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf12.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf12\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6f3e99-c3d1-408a-b040-0e97c07740a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 33s 38ms/step - loss: 1.5073 - accuracy: 0.7703 - val_loss: 0.4185 - val_accuracy: 0.9235\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.2979 - accuracy: 0.9245 - val_loss: 0.1634 - val_accuracy: 0.9643\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.1903 - accuracy: 0.9450 - val_loss: 0.3006 - val_accuracy: 0.9292\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.1640 - accuracy: 0.9523 - val_loss: 0.1912 - val_accuracy: 0.9558\n",
      "Epoch 5/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9550Restoring model weights from the end of the best epoch: 2.\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.1532 - accuracy: 0.9550 - val_loss: 0.1458 - val_accuracy: 0.9625\n",
      "Epoch 5: early stopping\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1360 - accuracy: 0.9663\n",
      "Train error: 4.50%\n",
      "Test error: 3.37%\n",
      "Duration: 159.50 seconds\n"
     ]
    }
   ],
   "source": [
    "conf13=Sequential()\n",
    " \n",
    "conf13.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"sigmoid\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf13.add(BatchNormalization())\n",
    "conf13.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"sigmoid\", kernel_initializer='glorot_uniform'))\n",
    "conf13.add(BatchNormalization())\n",
    "    \n",
    "conf13.add(Flatten())\n",
    "conf13.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf13.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf13.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf13.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf13\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1bbc50c-428e-4e93-9790-2babeb142b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 1.3094 - accuracy: 0.8188 - val_loss: 0.3604 - val_accuracy: 0.9395\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 31s 37ms/step - loss: 0.5032 - accuracy: 0.9162 - val_loss: 3.5604 - val_accuracy: 0.7640\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.2921 - accuracy: 0.9364 - val_loss: 1.1257 - val_accuracy: 0.8123\n",
      "Epoch 4/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9481Restoring model weights from the end of the best epoch: 1.\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.2007 - accuracy: 0.9481 - val_loss: 1.7328 - val_accuracy: 0.7953\n",
      "Epoch 4: early stopping\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3306 - accuracy: 0.9419\n",
      "Train error: 5.19%\n",
      "Test error: 5.81%\n",
      "Duration: 123.64 seconds\n"
     ]
    }
   ],
   "source": [
    "conf14=Sequential()\n",
    " \n",
    "conf14.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"tanh\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf14.add(BatchNormalization())\n",
    "conf14.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"tanh\", kernel_initializer='glorot_uniform'))\n",
    "conf14.add(BatchNormalization())\n",
    "    \n",
    "conf14.add(Flatten())\n",
    "conf14.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf14.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf14.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf14.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf14\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9bb8c4d-add8-4f01-a103-c69b6d002f15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 33s 38ms/step - loss: 1.1052 - accuracy: 0.8516 - val_loss: 0.4433 - val_accuracy: 0.9460\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.5079 - accuracy: 0.9239 - val_loss: 0.2077 - val_accuracy: 0.9628\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.2828 - accuracy: 0.9424 - val_loss: 0.2842 - val_accuracy: 0.9360\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.1787 - accuracy: 0.9538 - val_loss: 0.1528 - val_accuracy: 0.9582\n",
      "Epoch 5/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 0.1331 - accuracy: 0.9611Restoring model weights from the end of the best epoch: 2.\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.1331 - accuracy: 0.9611 - val_loss: 0.1546 - val_accuracy: 0.9563\n",
      "Epoch 5: early stopping\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1716 - accuracy: 0.9674\n",
      "Train error: 3.89%\n",
      "Test error: 3.26%\n",
      "Duration: 159.73 seconds\n"
     ]
    }
   ],
   "source": [
    "conf15=Sequential()\n",
    " \n",
    "conf15.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"leaky_relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf15.add(BatchNormalization())\n",
    "conf15.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"leaky_relu\", kernel_initializer='glorot_uniform'))\n",
    "conf15.add(BatchNormalization())\n",
    "    \n",
    "conf15.add(Flatten())\n",
    "conf15.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf15.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf15.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf15.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf15\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b3b7f25-6db8-4ee9-90e4-7f67f2d1a7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 29s 33ms/step - loss: 3.0000 - accuracy: 0.5222 - val_loss: 1.0471 - val_accuracy: 0.6810\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 28s 33ms/step - loss: 1.3195 - accuracy: 0.6096 - val_loss: 0.6619 - val_accuracy: 0.8202\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 28s 33ms/step - loss: 1.1200 - accuracy: 0.6505 - val_loss: 0.6428 - val_accuracy: 0.8177\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 28s 33ms/step - loss: 1.1134 - accuracy: 0.6566 - val_loss: 0.6836 - val_accuracy: 0.8062\n",
      "Epoch 5/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 1.1097 - accuracy: 0.6557Restoring model weights from the end of the best epoch: 2.\n",
      "844/844 [==============================] - 28s 33ms/step - loss: 1.1095 - accuracy: 0.6558 - val_loss: 0.6307 - val_accuracy: 0.8152\n",
      "Epoch 5: early stopping\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6488 - accuracy: 0.8286\n",
      "Train error: 34.42%\n",
      "Test error: 17.14%\n",
      "Duration: 141.16 seconds\n"
     ]
    }
   ],
   "source": [
    "conf16=Sequential()\n",
    " \n",
    "conf16.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"linear\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf16.add(BatchNormalization())\n",
    "conf16.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"linear\", kernel_initializer='glorot_uniform'))\n",
    "conf16.add(BatchNormalization())\n",
    "    \n",
    "conf16.add(Flatten())\n",
    "conf16.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf16.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf16.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf16.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf16\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "216c0d22-7591-441c-9d9a-6ac7eeea8a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 33s 38ms/step - loss: 0.5621 - accuracy: 0.8765 - val_loss: 1.8827 - val_accuracy: 0.8313\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 34s 41ms/step - loss: 0.3307 - accuracy: 0.9304 - val_loss: 2.5067 - val_accuracy: 0.8613\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.2711 - accuracy: 0.9426 - val_loss: 2.0608 - val_accuracy: 0.9047\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.2134 - accuracy: 0.9508 - val_loss: 2.1406 - val_accuracy: 0.8757\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.1744 - accuracy: 0.9584 - val_loss: 0.8352 - val_accuracy: 0.9177\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.9238 - accuracy: 0.9176\n",
      "Train error: 4.16%\n",
      "Test error: 8.24%\n",
      "Duration: 163.43 seconds\n"
     ]
    }
   ],
   "source": [
    "conf17=Sequential()\n",
    " \n",
    "conf17.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"exponential\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf17.add(BatchNormalization())\n",
    "conf17.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"exponential\", kernel_initializer='glorot_uniform'))\n",
    "conf17.add(BatchNormalization())\n",
    "    \n",
    "conf17.add(Flatten())\n",
    "conf17.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf17.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf17.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf17.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf17\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c325b134-a97d-42e5-b077-a7c01d99a2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 35s 41ms/step - loss: 0.5448 - accuracy: 0.8421 - val_loss: 0.1498 - val_accuracy: 0.9587\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 35s 41ms/step - loss: 0.1603 - accuracy: 0.9544 - val_loss: 0.1090 - val_accuracy: 0.9675\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 34s 40ms/step - loss: 0.1097 - accuracy: 0.9675 - val_loss: 0.1485 - val_accuracy: 0.9585\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 34s 40ms/step - loss: 0.0935 - accuracy: 0.9716 - val_loss: 0.0734 - val_accuracy: 0.9785\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 34s 40ms/step - loss: 0.0860 - accuracy: 0.9741 - val_loss: 0.0586 - val_accuracy: 0.9838\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0518 - accuracy: 0.9848\n",
      "Train error: 2.59%\n",
      "Test error: 1.52%\n",
      "Duration: 172.46 seconds\n"
     ]
    }
   ],
   "source": [
    "conf18=Sequential()\n",
    " \n",
    "conf18.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf18.add(BatchNormalization())\n",
    "conf18.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf18.add(BatchNormalization())\n",
    "    \n",
    "conf18.add(Flatten())\n",
    "conf18.add(Dense(32,activation=\"relu\"))\n",
    "conf18.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf18.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf18.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf18.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf18\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc5e99e4-fd1b-401a-94db-570efb89249e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 42s 49ms/step - loss: 0.4117 - accuracy: 0.8859 - val_loss: 0.1046 - val_accuracy: 0.9678\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 40s 48ms/step - loss: 0.1458 - accuracy: 0.9586 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 43s 50ms/step - loss: 0.1106 - accuracy: 0.9672 - val_loss: 0.0881 - val_accuracy: 0.9733\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 41s 49ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 0.0616 - val_accuracy: 0.9838\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 42s 50ms/step - loss: 0.0780 - accuracy: 0.9769 - val_loss: 0.0658 - val_accuracy: 0.9805\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0507 - accuracy: 0.9859\n",
      "Train error: 2.31%\n",
      "Test error: 1.41%\n",
      "Duration: 207.98 seconds\n"
     ]
    }
   ],
   "source": [
    "conf19=Sequential()\n",
    " \n",
    "conf19.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf19.add(BatchNormalization())\n",
    "conf19.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf19.add(BatchNormalization())\n",
    "    \n",
    "conf19.add(Flatten())\n",
    "conf19.add(Dense(64,activation=\"relu\"))\n",
    "conf19.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf19.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf19.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf19.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf19\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5ba1851-2b9b-4906-9352-17893b23bcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 53s 62ms/step - loss: 0.4167 - accuracy: 0.8881 - val_loss: 0.1421 - val_accuracy: 0.9568\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 53s 62ms/step - loss: 0.1421 - accuracy: 0.9581 - val_loss: 0.0773 - val_accuracy: 0.9790\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 52s 62ms/step - loss: 0.1083 - accuracy: 0.9690 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 53s 62ms/step - loss: 0.0879 - accuracy: 0.9744 - val_loss: 0.0829 - val_accuracy: 0.9758\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 54s 64ms/step - loss: 0.0860 - accuracy: 0.9754 - val_loss: 0.0633 - val_accuracy: 0.9835\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0476 - accuracy: 0.9856\n",
      "Train error: 2.46%\n",
      "Test error: 1.44%\n",
      "Duration: 264.65 seconds\n"
     ]
    }
   ],
   "source": [
    "conf20=Sequential()\n",
    " \n",
    "conf20.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf20.add(BatchNormalization())\n",
    "conf20.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf20.add(BatchNormalization())\n",
    "    \n",
    "conf20.add(Flatten())\n",
    "conf20.add(Dense(128,activation=\"relu\"))\n",
    "conf20.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf20.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf20.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf20.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf20\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8917ec6-dbfd-497e-8864-4b828fdde012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.7143 - accuracy: 0.8805 - val_loss: 0.2739 - val_accuracy: 0.9457\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.2384 - accuracy: 0.9468 - val_loss: 0.2425 - val_accuracy: 0.9423\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1567 - accuracy: 0.9610 - val_loss: 0.1806 - val_accuracy: 0.9568\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1269 - accuracy: 0.9669 - val_loss: 0.0991 - val_accuracy: 0.9758\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1058 - accuracy: 0.9719 - val_loss: 0.1019 - val_accuracy: 0.9758\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0824 - accuracy: 0.9764\n",
      "Train error: 2.81%\n",
      "Test error: 2.36%\n",
      "Duration: 149.08 seconds\n"
     ]
    }
   ],
   "source": [
    "conf21=Sequential()\n",
    " \n",
    "conf21.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf21.add(BatchNormalization())\n",
    "conf21.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf21.add(BatchNormalization())\n",
    "    \n",
    "conf21.add(Flatten())\n",
    "conf21.add(Dense(10,activation=\"sigmoid\"))\n",
    "    \n",
    "conf21.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf21.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf21.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf21\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7d7a26d-d9a2-4ca5-a400-e6f9797dc3ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 8.1908 - accuracy: 0.1397 - val_loss: 7.9260 - val_accuracy: 0.1387\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 8.4801 - accuracy: 0.1591 - val_loss: 8.5392 - val_accuracy: 0.1563\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 8.1315 - accuracy: 0.1241 - val_loss: 8.2941 - val_accuracy: 0.1242\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 8.6579 - accuracy: 0.1215 - val_loss: 10.0110 - val_accuracy: 0.1172\n",
      "Epoch 5/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 8.7923 - accuracy: 0.1175Restoring model weights from the end of the best epoch: 2.\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 8.7941 - accuracy: 0.1175 - val_loss: 7.3142 - val_accuracy: 0.1128\n",
      "Epoch 5: early stopping\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 8.3676 - accuracy: 0.1572\n",
      "Train error: 88.25%\n",
      "Test error: 84.28%\n",
      "Duration: 149.58 seconds\n"
     ]
    }
   ],
   "source": [
    "conf22=Sequential()\n",
    " \n",
    "conf22.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf22.add(BatchNormalization())\n",
    "conf22.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf22.add(BatchNormalization())\n",
    "    \n",
    "conf22.add(Flatten())\n",
    "conf22.add(Dense(10,activation=\"linear\"))\n",
    "    \n",
    "conf22.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf22.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf22.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf22\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8e31b26-cff7-4541-a37a-161ee2816f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 54s 63ms/step - loss: 0.5896 - accuracy: 0.8294 - val_loss: 0.1401 - val_accuracy: 0.9583\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 53s 62ms/step - loss: 0.2379 - accuracy: 0.9315 - val_loss: 0.1616 - val_accuracy: 0.9535\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 53s 63ms/step - loss: 0.1681 - accuracy: 0.9511 - val_loss: 0.0525 - val_accuracy: 0.9855\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 55s 65ms/step - loss: 0.1379 - accuracy: 0.9594 - val_loss: 0.1118 - val_accuracy: 0.9702\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 59s 70ms/step - loss: 0.1223 - accuracy: 0.9648 - val_loss: 0.0649 - val_accuracy: 0.9852\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0483 - accuracy: 0.9871\n",
      "Train error: 3.52%\n",
      "Test error: 1.29%\n",
      "Duration: 272.95 seconds\n"
     ]
    }
   ],
   "source": [
    "conf23=Sequential()\n",
    " \n",
    "conf23.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf23.add(BatchNormalization())\n",
    "conf23.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf23.add(BatchNormalization())\n",
    "    \n",
    "conf23.add(Flatten())\n",
    "conf23.add(Dense(128,activation=\"relu\"))\n",
    "conf23.add(Dropout(0.2))\n",
    "conf23.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf23.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf23.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf23.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf23\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f936357-29d1-4892-b4b2-207b57e43dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 59s 69ms/step - loss: 1.0491 - accuracy: 0.6745 - val_loss: 0.1236 - val_accuracy: 0.9668\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 57s 67ms/step - loss: 0.4134 - accuracy: 0.8730 - val_loss: 0.1219 - val_accuracy: 0.9740\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 57s 67ms/step - loss: 0.3017 - accuracy: 0.9092 - val_loss: 0.0848 - val_accuracy: 0.9770\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 52s 62ms/step - loss: 0.2320 - accuracy: 0.9313 - val_loss: 0.0566 - val_accuracy: 0.9843\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 52s 62ms/step - loss: 0.2063 - accuracy: 0.9391 - val_loss: 0.0603 - val_accuracy: 0.9845\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0460 - accuracy: 0.9874\n",
      "Train error: 6.09%\n",
      "Test error: 1.26%\n",
      "Duration: 277.37 seconds\n"
     ]
    }
   ],
   "source": [
    "conf24=Sequential()\n",
    " \n",
    "conf24.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf24.add(BatchNormalization())\n",
    "conf24.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf24.add(BatchNormalization())\n",
    "    \n",
    "conf24.add(Flatten())\n",
    "conf24.add(Dense(128,activation=\"relu\"))\n",
    "conf24.add(Dropout(0.5))\n",
    "conf24.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf24.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf24.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf24.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf24\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4fb52b3-a12c-460f-b28d-dd5080dbbb5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 17s 19ms/step - loss: 0.2431 - accuracy: 0.9253 - val_loss: 0.1339 - val_accuracy: 0.9648\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.1079 - accuracy: 0.9667 - val_loss: 0.0784 - val_accuracy: 0.9783\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.0875 - accuracy: 0.9739 - val_loss: 0.2356 - val_accuracy: 0.9180\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.0772 - accuracy: 0.9776 - val_loss: 0.0792 - val_accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.0655 - accuracy: 0.9801 - val_loss: 0.0579 - val_accuracy: 0.9843\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9858\n",
      "Train error: 1.99%\n",
      "Test error: 1.42%\n",
      "Duration: 81.44 seconds\n"
     ]
    }
   ],
   "source": [
    "conf25=Sequential()\n",
    " \n",
    "conf25.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf25.add(MaxPooling2D(pool_size=(2,2)))\n",
    "conf25.add(BatchNormalization())\n",
    "conf25.add(Conv2D(filters=128, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf25.add(MaxPooling2D(pool_size=(2,2)))\n",
    "conf25.add(BatchNormalization())\n",
    "    \n",
    "conf25.add(Flatten())\n",
    "conf25.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf25.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf25.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf25.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf25\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22a15260-f9e5-4cca-88da-523ce27eaba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1688/1688 [==============================] - 90s 53ms/step - loss: 0.2093 - accuracy: 0.9409 - val_loss: 0.1131 - val_accuracy: 0.9765\n",
      "Epoch 2/30\n",
      "1688/1688 [==============================] - 90s 53ms/step - loss: 0.1056 - accuracy: 0.9711 - val_loss: 0.0596 - val_accuracy: 0.9882\n",
      "Epoch 3/30\n",
      "1688/1688 [==============================] - 89s 53ms/step - loss: 0.0768 - accuracy: 0.9781 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 4/30\n",
      "1688/1688 [==============================] - 95s 56ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.0672 - val_accuracy: 0.9835\n",
      "Epoch 5/30\n",
      "1688/1688 [==============================] - 98s 58ms/step - loss: 0.0578 - accuracy: 0.9835 - val_loss: 0.0794 - val_accuracy: 0.9815\n",
      "Epoch 6/30\n",
      "1688/1688 [==============================] - 99s 58ms/step - loss: 0.0540 - accuracy: 0.9843 - val_loss: 0.0407 - val_accuracy: 0.9903\n",
      "Epoch 7/30\n",
      "1688/1688 [==============================] - 91s 54ms/step - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.0531 - val_accuracy: 0.9892\n",
      "Epoch 8/30\n",
      "1688/1688 [==============================] - 89s 52ms/step - loss: 0.0441 - accuracy: 0.9873 - val_loss: 0.0416 - val_accuracy: 0.9923\n",
      "Epoch 9/30\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.0531 - val_accuracy: 0.9917\n",
      "Epoch 10/30\n",
      "1688/1688 [==============================] - 89s 52ms/step - loss: 0.0388 - accuracy: 0.9891 - val_loss: 0.0725 - val_accuracy: 0.9898\n",
      "Epoch 11/30\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.1135 - val_accuracy: 0.9880\n",
      "Epoch 12/30\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.3436 - val_accuracy: 0.9842\n",
      "Epoch 13/30\n",
      "1688/1688 [==============================] - 92s 54ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.0691 - val_accuracy: 0.9875\n",
      "Epoch 14/30\n",
      "1688/1688 [==============================] - 95s 56ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.0605 - val_accuracy: 0.9915\n",
      "Epoch 15/30\n",
      "1688/1688 [==============================] - 91s 54ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.2222 - val_accuracy: 0.9885\n",
      "Epoch 16/30\n",
      "1687/1688 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9907Restoring model weights from the end of the best epoch: 8.\n",
      "1688/1688 [==============================] - 89s 53ms/step - loss: 0.0322 - accuracy: 0.9907 - val_loss: 0.1387 - val_accuracy: 0.9885\n",
      "Epoch 16: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0276 - accuracy: 0.9936\n",
      "Train error: 0.93%\n",
      "Test error: 0.64%\n",
      "Duration: 1459.08 seconds\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=8, \n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True)\n",
    "\n",
    "final=Sequential()\n",
    " \n",
    "final.add(Conv2D(filters=128, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
    "final.add(MaxPooling2D(pool_size=(2,2)))\n",
    "final.add(BatchNormalization())\n",
    "final.add(Conv2D(filters=256, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "final.add(MaxPooling2D(pool_size=(2,2)))\n",
    "final.add(BatchNormalization())\n",
    "final.add(Conv2D(filters=512, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "final.add(MaxPooling2D(pool_size=(2,2)))\n",
    "final.add(BatchNormalization())\n",
    "    \n",
    "final.add(Flatten())\n",
    "final.add(Dense(1024,activation=\"relu\"))\n",
    "final.add(Dropout(0.2))\n",
    "final.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "final.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = final.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=32),\n",
    "    epochs=30,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = final.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"final\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a58bee0-28b2-4677-adc1-4c1d2437b86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1688/1688 [==============================] - 19s 10ms/step - loss: 0.1933 - accuracy: 0.9408 - val_loss: 0.0658 - val_accuracy: 0.9807\n",
      "Epoch 2/30\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0862 - accuracy: 0.9736 - val_loss: 0.0662 - val_accuracy: 0.9795\n",
      "Epoch 3/30\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.0397 - val_accuracy: 0.9887\n",
      "Epoch 4/30\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
      "Epoch 5/30\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.0436 - val_accuracy: 0.9878\n",
      "Epoch 6/30\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 0.0582 - val_accuracy: 0.9848\n",
      "Epoch 7/30\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.0424 - val_accuracy: 0.9888\n",
      "Epoch 8/30\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.0321 - val_accuracy: 0.9932\n",
      "Epoch 9/30\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.0381 - val_accuracy: 0.9890\n",
      "Epoch 10/30\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.0560 - val_accuracy: 0.9867\n",
      "Epoch 11/30\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0477 - val_accuracy: 0.9873\n",
      "Epoch 12/30\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0347 - accuracy: 0.9893 - val_loss: 0.0332 - val_accuracy: 0.9937\n",
      "Epoch 13/30\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0349 - val_accuracy: 0.9927\n",
      "Epoch 14/30\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0334 - accuracy: 0.9901 - val_loss: 0.0321 - val_accuracy: 0.9928\n",
      "Epoch 15/30\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0480 - val_accuracy: 0.9898\n",
      "Epoch 16/30\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.0367 - val_accuracy: 0.9927\n",
      "Epoch 17/30\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0354 - val_accuracy: 0.9917\n",
      "Epoch 18/30\n",
      "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.0330 - val_accuracy: 0.9923\n",
      "Epoch 19/30\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0415 - val_accuracy: 0.9920\n",
      "Epoch 20/30\n",
      "1686/1688 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9911Restoring model weights from the end of the best epoch: 12.\n",
      "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 20: early stopping\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9940\n",
      "Train error: 0.89%\n",
      "Test error: 0.60%\n",
      "Duration: 317.77 seconds\n"
     ]
    }
   ],
   "source": [
    "best=Sequential()\n",
    " \n",
    "best.add(Conv2D(filters=32, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
    "best.add(MaxPooling2D(pool_size=(2,2)))\n",
    "best.add(BatchNormalization())\n",
    "best.add(Conv2D(filters=64, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "best.add(MaxPooling2D(pool_size=(2,2)))\n",
    "best.add(BatchNormalization())\n",
    "best.add(Conv2D(filters=128, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "best.add(MaxPooling2D(pool_size=(2,2)))\n",
    "best.add(BatchNormalization())\n",
    "    \n",
    "best.add(Flatten())\n",
    "best.add(Dense(256,activation=\"relu\"))\n",
    "best.add(Dropout(0.2))\n",
    "best.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "best.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = best.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=32),\n",
    "    epochs=30,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = best.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"best\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef45a864-ff2a-40c6-8741-c37bc8aa979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Configuration Train Error Test Error Duration(seconds)\n",
      "0          model       2.91%      2.84%            162.14\n",
      "1          conf1       2.84%      2.76%            165.65\n",
      "2          conf2       2.98%      2.04%            149.57\n",
      "3          conf3       3.94%      2.57%             89.35\n",
      "4          conf4       2.02%      1.47%            295.96\n",
      "5          conf5       2.94%      2.27%            152.92\n",
      "6          conf6       2.60%      1.69%            242.43\n",
      "7          conf7       2.88%      1.78%             72.46\n",
      "8          conf8       3.01%      2.21%            462.22\n",
      "9          conf9      23.27%     46.66%            115.73\n",
      "10        conf10       2.46%      1.20%            227.57\n",
      "11        conf11       2.94%      2.38%             60.68\n",
      "12        conf12       4.45%      2.12%             52.04\n",
      "13        conf13       4.50%      3.37%            159.50\n",
      "14        conf14       5.19%      5.81%            123.64\n",
      "15        conf15       3.89%      3.26%            159.73\n",
      "16        conf16      34.42%     17.14%            141.16\n",
      "17        conf17       4.16%      8.24%            163.43\n",
      "18        conf18       2.59%      1.52%            172.46\n",
      "19        conf19       2.31%      1.41%            207.98\n",
      "20        conf20       2.46%      1.44%            264.65\n",
      "21        conf21       2.81%      2.36%            149.08\n",
      "22        conf22      88.25%     84.28%            149.58\n",
      "23        conf23       3.52%      1.29%            272.95\n",
      "24        conf24       6.09%      1.26%            277.37\n",
      "25        conf25       1.99%      1.42%             81.44\n",
      "26         final       0.93%      0.64%           1459.08\n",
      "27          best       0.89%      0.60%            317.77\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22292668-d5c3-431e-a6c0-9d351d9b17f1",
   "metadata": {},
   "source": [
    "## Daftar Referensi\n",
    "1. https://paperswithcode.com/datasets?task=image-classification\n",
    "2. https://keras.io/api/datasets/mnist/\n",
    "3. https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner\n",
    "4. https://keras.io/layers/core/\n",
    "5. https://keras.io/layers/convolutional/\n",
    "6. https://keras.io/layers/pooling/\n",
    "7. https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "8. https://keras.io/api/callbacks/early_stopping/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
