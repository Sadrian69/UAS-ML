{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96a7315-43c1-4604-8fc4-a663cf9f834f",
   "metadata": {},
   "source": [
    "# Laporan Project UAS Machine Learning\n",
    "\n",
    "Adi Christian C14210091\\\n",
    "Meike Surajiman C14210116\\\n",
    "Steven Adrian Gracia C14210171\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a7b788-8cc8-4a27-bd30-01365b57a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "aman\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "print(\"aman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64092b7a-4076-4c22-8a88-2a665f240f39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pengenalan dataset\n",
    "Dataset yang kami pakai adalah [MNIST](http://yann.lecun.com/exdb/mnist/) . Dataset ini berisi beberapa gambar angka yang ditulis tangan. Dataset ini memberikan kesempatan bagi algoritma machine learning untuk mengidentifikasi digit yang benar dari gambar-gambar tersebut. Dataset yang kami gunakan berasal langsung dari keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8590500e-b079-4ad4-9ba1-f1b5537cc836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facffc80-643f-4b87-985b-eb68263286dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "Ada beberapa hal yang perlu dilakukan sebelum memproses dataset tersebut, diantaranya:\n",
    "1. Normalisasi\n",
    "2. Reshape\n",
    "3. Label encoding\n",
    "4. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585228b-efbd-48f6-85cd-0e33a471505d",
   "metadata": {},
   "source": [
    "1. Data yang dimuat berada di range 0 sampai 255. Supaya CNN konvergen lebih cepat, bisa dilakukan normalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677ed96c-b818-40b1-9f75-bc0975899ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8986492e-3429-44e1-a4be-6d748dd185b6",
   "metadata": {},
   "source": [
    "2. Array X akan lebih mudah divisualisasi jika direshape sebagai \"gambar\" dengan height dan width 28px beserta grayscalenya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ef1c7a-eaf0-44a2-9b73-47e73db83cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((-1,28,28,1)).astype(\"float32\")\n",
    "test_images = test_images.reshape((-1,28,28,1)).astype(\"float32\")\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c314c5-4c43-41c1-a397-48429cda7b74",
   "metadata": {},
   "source": [
    "3. Karena y (label tiap gambar) tidak memiliki relasi ordinal, maka dilakukan one-hot encoding sehingga hasil dari CNN tidak terpengaruh selisih angka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1242fbf-2849-4c8d-8e04-28ac7be1ed46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23474624-0005-4450-92be-e6406da9d3ed",
   "metadata": {},
   "source": [
    "4. Split data untuk train dan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7e1e2e-1a51-42b6-96ad-909fdc2b73fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28, 1) (6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "print(train_images.shape, val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88f673-4870-4e6f-b1b3-639d9ff193d1",
   "metadata": {},
   "source": [
    "Contoh visualisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6e6584-1ce8-4cb2-8253-38c5ae30a863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = train_images.reshape(train_images.shape[0], 28, 28)\n",
    "\n",
    "fig, axis = plt.subplots(1, 5, figsize=(20, 10))\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    ax.imshow(temp[i], cmap='binary')\n",
    "    digit = train_labels[i].argmax()\n",
    "    ax.set(title = f\"Real Number is {digit}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843affb-6a75-486c-9752-481582b9a798",
   "metadata": {},
   "source": [
    "Untuk menghindari overfitting, dataset yang sudah ada diperluas dengan menggunakan data augmentation. Caranya adalah memberi sedikit variasi untuk setiap data dengan cara memperbesar/kecil, mengubah tempat, dll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f352eb-4ebf-4bfb-bdb8-5e495d73785e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False, \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=15,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False)  \n",
    "# akan digunakan saat fitting nanti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399aa2d5-c90e-4ca2-9bc0-c7d539fbd1c0",
   "metadata": {},
   "source": [
    "## Metode CNN: AlexNet\n",
    "AlexNet adalah sebuah arsitektur CNN yang cukup simpel. Di sini akan diimplementasikan Alexnet dari awal menggunakan Keras Sequential API dengan cara menumpuk layer CNN satu sama lain.\n",
    "Ada beberapa jenis layer CNN di AlexNet:\n",
    "- Convolutional layer: sebuah perkalian dot product antara 2 elemen, berisi operasi convolutional antara filter dan image\n",
    "- Batch Normalisation layer: layer tambahan yang menstandarisasi dan menormalisasi nilai input\n",
    "- Max Pooling layer: mencari nilai max dari sebuah range sebagai output\n",
    "- Flatten layer: mengubah image menjadi array 1D\n",
    "- Dense layer: berisi banyak neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7af4cb-fdcd-4ba7-a3a2-e5a95332044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping untuk berhenti dahulu jika sudah fit\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=3, \n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a78fef4-a57d-4073-a603-57294e00554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 26, 26, 64)        256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 24, 24, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                368650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406730 (1.55 MB)\n",
      "Trainable params: 406474 (1.55 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab00126-ae61-408e-986c-9297369342d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steven Adrian\\anaconda3\\envs\\islp\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.6748 - accuracy: 0.8851 - val_loss: 0.1612 - val_accuracy: 0.9572\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.2102 - accuracy: 0.9506 - val_loss: 0.1419 - val_accuracy: 0.9662\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1518 - accuracy: 0.9622 - val_loss: 0.0964 - val_accuracy: 0.9742\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1297 - accuracy: 0.9653 - val_loss: 0.1407 - val_accuracy: 0.9657\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1034 - accuracy: 0.9712 - val_loss: 0.0622 - val_accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909c2d1f-9c90-4054-99a9-67ca0f20b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0682 - accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3fa055-be9b-4319-b926-a1098c3719bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 2.88%\n",
      "Test error: 1.93%\n",
      "Duration: 149.24 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9043c15b-8107-4163-a760-43ee05d12593",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append({\n",
    "    \"Configuration\": \"model\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ff5f7-9c43-47a8-81a3-de37ea1a68f1",
   "metadata": {},
   "source": [
    "## Konfigurasi parameter CNN\n",
    "Kami mencoba beberapa konfigurasi parameter di CNN. Diantaranya:\n",
    "- Batch Size\n",
    "- Kernel Initializer (HE/Glorot)\n",
    "- Jumlah hidden layer\n",
    "- Jumlah channels hidden layer\n",
    "- Kernel size hidden layer\n",
    "- Stride hidden layer\n",
    "- Activation function hidden layer\n",
    "- Jumlah neuron output layer\n",
    "- Activation function output layer\n",
    "- Loss function\n",
    "- Regularization\n",
    "- Max pooling\n",
    "\n",
    "\n",
    "Data yang kami dapatkan sebagai berikut dengan implementasi di bawahnya\n",
    "| CONFIGURATION | LAYERS | REGULARIZATION | TRAIN ERROR | TEST ERROR | DURATION(seconds) |\n",
    "|---------------|--------|----------------|-------------|------------|----------|\n",
    "| Model         |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf1         |Batch=32, Epoch=5,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf2         |Batch=128, Epoch=5,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf3         |Batch=64, Epoch=3,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf4         |Batch=64, Epoch=10,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf5         |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=2,ReLu,HE<br>C64x28x28,K=3,S=2,ReLu,HE<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf6         |Batch=64, Epoch=5,<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>C64x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf7         |Batch=64, Epoch=5,<br>C32x28x28,K=3,S=2,ReLu,Glorot<br>C32x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf8         |Batch=64, Epoch=5,<br>C128x28x28,K=3,S=2,ReLu,Glorot<br>C128x28x28,K=3,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf9         |Batch=64, Epoch=5,<br>C128x28x28,K=1,S=2,ReLu,Glorot<br>C128x28x28,K=1,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "| Conf10        |Batch=64, Epoch=5,<br>C128x28x28,K=5,S=2,ReLu,Glorot<br>C128x28x28,K=5,S=2,ReLu,Glorot<br>F10,softmax,cross-entropy loss||%|%||\n",
    "\n",
    "Dari data yang kami dapatkan, konfigurasi yang terbaik adalah ConfXX dengan train error XX% dan test error XX%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e43b28-6004-4154-ae64-3f2b4d3be14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 32s 18ms/step - loss: 0.7965 - accuracy: 0.8840 - val_loss: 0.2565 - val_accuracy: 0.9397\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.2154 - accuracy: 0.9490 - val_loss: 0.1070 - val_accuracy: 0.9658\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 30s 18ms/step - loss: 0.1463 - accuracy: 0.9604 - val_loss: 0.0727 - val_accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 30s 18ms/step - loss: 0.1068 - accuracy: 0.9693 - val_loss: 0.0672 - val_accuracy: 0.9807\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.0975 - accuracy: 0.9716 - val_loss: 0.0559 - val_accuracy: 0.9825\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0460 - accuracy: 0.9854\n",
      "Train error: 2.84%\n",
      "Test error: 1.46%\n",
      "Duration: 155.76 seconds\n"
     ]
    }
   ],
   "source": [
    "conf1=Sequential()\n",
    " \n",
    "conf1.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf1.add(BatchNormalization())\n",
    "conf1.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf1.add(BatchNormalization())\n",
    "    \n",
    "conf1.add(Flatten())\n",
    "conf1.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf1.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=32),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf1.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf1\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bebf2e90-032a-4124-87c1-6aa95ee073f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 30s 70ms/step - loss: 0.6879 - accuracy: 0.8767 - val_loss: 3.0191 - val_accuracy: 0.3137\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 29s 68ms/step - loss: 0.2685 - accuracy: 0.9462 - val_loss: 0.1976 - val_accuracy: 0.9537\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 29s 68ms/step - loss: 0.1651 - accuracy: 0.9609 - val_loss: 0.2201 - val_accuracy: 0.9467\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 29s 68ms/step - loss: 0.1376 - accuracy: 0.9647 - val_loss: 0.1379 - val_accuracy: 0.9708\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 29s 68ms/step - loss: 0.1114 - accuracy: 0.9711 - val_loss: 0.1685 - val_accuracy: 0.9602\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1671 - accuracy: 0.9606\n",
      "Train error: 2.89%\n",
      "Test error: 3.94%\n",
      "Duration: 144.78 seconds\n"
     ]
    }
   ],
   "source": [
    "conf2=Sequential()\n",
    " \n",
    "conf2.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf2.add(BatchNormalization())\n",
    "conf2.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf2.add(BatchNormalization())\n",
    "    \n",
    "conf2.add(Flatten())\n",
    "conf2.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf2.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=128),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf2.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf2\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba082e84-e55a-4c7e-aa35-763a3bc680a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.7514 - accuracy: 0.8801 - val_loss: 1.0666 - val_accuracy: 0.8098\n",
      "Epoch 2/3\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.2274 - accuracy: 0.9481 - val_loss: 0.1739 - val_accuracy: 0.9598\n",
      "Epoch 3/3\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.1664 - accuracy: 0.9600 - val_loss: 0.2494 - val_accuracy: 0.9360\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2572 - accuracy: 0.9343\n",
      "Train error: 4.00%\n",
      "Test error: 6.57%\n",
      "Duration: 95.11 seconds\n"
     ]
    }
   ],
   "source": [
    "conf3=Sequential()\n",
    " \n",
    "conf3.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf3.add(BatchNormalization())\n",
    "conf3.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf3.add(BatchNormalization())\n",
    "    \n",
    "conf3.add(Flatten())\n",
    "conf3.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf3.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=3,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf3.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf3\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e94a069c-78bb-4fe8-b50d-e1faa3911ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.7053 - accuracy: 0.8826 - val_loss: 0.2213 - val_accuracy: 0.9605\n",
      "Epoch 2/10\n",
      "844/844 [==============================] - 29s 35ms/step - loss: 0.2247 - accuracy: 0.9474 - val_loss: 0.1470 - val_accuracy: 0.9628\n",
      "Epoch 3/10\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.1566 - accuracy: 0.9610 - val_loss: 0.1464 - val_accuracy: 0.9662\n",
      "Epoch 4/10\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.1249 - accuracy: 0.9666 - val_loss: 0.1023 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.1034 - accuracy: 0.9709 - val_loss: 0.1295 - val_accuracy: 0.9680\n",
      "Epoch 6/10\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.0944 - accuracy: 0.9731 - val_loss: 0.0868 - val_accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "844/844 [==============================] - 33s 39ms/step - loss: 0.0811 - accuracy: 0.9767 - val_loss: 0.1043 - val_accuracy: 0.9733\n",
      "Epoch 8/10\n",
      "844/844 [==============================] - 31s 37ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.0967 - val_accuracy: 0.9715\n",
      "Epoch 9/10\n",
      "843/844 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9788Restoring model weights from the end of the best epoch: 6.\n",
      "844/844 [==============================] - 31s 37ms/step - loss: 0.0722 - accuracy: 0.9788 - val_loss: 0.0869 - val_accuracy: 0.9733\n",
      "Epoch 9: early stopping\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0707 - accuracy: 0.9812\n",
      "Train error: 2.12%\n",
      "Test error: 1.88%\n",
      "Duration: 280.47 seconds\n"
     ]
    }
   ],
   "source": [
    "conf4=Sequential()\n",
    " \n",
    "conf4.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf4.add(BatchNormalization())\n",
    "conf4.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf4.add(BatchNormalization())\n",
    "    \n",
    "conf4.add(Flatten())\n",
    "conf4.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf4.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf4.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=10,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf4.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf4\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d71d022a-8248-43f3-a307-6b0031d81559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 32s 37ms/step - loss: 0.7977 - accuracy: 0.8863 - val_loss: 0.3437 - val_accuracy: 0.9503\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 31s 37ms/step - loss: 0.3016 - accuracy: 0.9479 - val_loss: 0.2333 - val_accuracy: 0.9580\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1941 - accuracy: 0.9609 - val_loss: 0.1408 - val_accuracy: 0.9732\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1379 - accuracy: 0.9674 - val_loss: 0.0937 - val_accuracy: 0.9785\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.1122 - accuracy: 0.9723 - val_loss: 0.0712 - val_accuracy: 0.9810\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0685 - accuracy: 0.9811\n",
      "Train error: 2.77%\n",
      "Test error: 1.89%\n",
      "Duration: 152.13 seconds\n"
     ]
    }
   ],
   "source": [
    "conf5=Sequential()\n",
    " \n",
    "conf5.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
    "conf5.add(BatchNormalization())\n",
    "conf5.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "conf5.add(BatchNormalization())\n",
    "    \n",
    "conf5.add(Flatten())\n",
    "conf5.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf5.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf5.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf5.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf5\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85173590-2e1e-409f-8a60-a6b5cf71486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 53s 62ms/step - loss: 0.7125 - accuracy: 0.8965 - val_loss: 0.2344 - val_accuracy: 0.9612\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 48s 57ms/step - loss: 0.3166 - accuracy: 0.9543 - val_loss: 0.1580 - val_accuracy: 0.9730\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 46s 54ms/step - loss: 0.2027 - accuracy: 0.9655 - val_loss: 0.1238 - val_accuracy: 0.9753\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 49s 58ms/step - loss: 0.1426 - accuracy: 0.9706 - val_loss: 0.0697 - val_accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 51s 61ms/step - loss: 0.1097 - accuracy: 0.9752 - val_loss: 0.0910 - val_accuracy: 0.9782\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.0778 - accuracy: 0.9813\n",
      "Train error: 2.48%\n",
      "Test error: 1.87%\n",
      "Duration: 247.18 seconds\n"
     ]
    }
   ],
   "source": [
    "conf6=Sequential()\n",
    " \n",
    "conf6.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf6.add(BatchNormalization())\n",
    "conf6.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf6.add(BatchNormalization())\n",
    "conf6.add(Conv2D(filters=64, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf6.add(BatchNormalization())\n",
    "    \n",
    "conf6.add(Flatten())\n",
    "conf6.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf6.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf6.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf6.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf6\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e89aea7-76cc-4b7b-b924-39e71a157f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 16s 18ms/step - loss: 0.4499 - accuracy: 0.8898 - val_loss: 0.2224 - val_accuracy: 0.9387\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 15s 17ms/step - loss: 0.1797 - accuracy: 0.9515 - val_loss: 0.0984 - val_accuracy: 0.9745\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 17s 20ms/step - loss: 0.1403 - accuracy: 0.9615 - val_loss: 0.1039 - val_accuracy: 0.9682\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 15s 18ms/step - loss: 0.1125 - accuracy: 0.9671 - val_loss: 0.1218 - val_accuracy: 0.9677\n",
      "Epoch 5/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9718Restoring model weights from the end of the best epoch: 2.\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.0973 - accuracy: 0.9717 - val_loss: 0.0894 - val_accuracy: 0.9733\n",
      "Epoch 5: early stopping\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9749\n",
      "Train error: 2.83%\n",
      "Test error: 2.51%\n",
      "Duration: 79.38 seconds\n"
     ]
    }
   ],
   "source": [
    "conf7=Sequential()\n",
    " \n",
    "conf7.add(Conv2D(filters=32, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf7.add(BatchNormalization())\n",
    "conf7.add(Conv2D(filters=32, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf7.add(BatchNormalization())\n",
    "    \n",
    "conf7.add(Flatten())\n",
    "conf7.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf7.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf7.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf7.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf7\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95062a10-d7b7-4bc4-81af-334b2a3d7909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 100s 117ms/step - loss: 0.9926 - accuracy: 0.8837 - val_loss: 0.1163 - val_accuracy: 0.9693\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 96s 113ms/step - loss: 0.2018 - accuracy: 0.9508 - val_loss: 0.1470 - val_accuracy: 0.9653\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 95s 113ms/step - loss: 0.1533 - accuracy: 0.9610 - val_loss: 0.1124 - val_accuracy: 0.9733\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 101s 120ms/step - loss: 0.1234 - accuracy: 0.9673 - val_loss: 0.1075 - val_accuracy: 0.9720\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 97s 115ms/step - loss: 0.1009 - accuracy: 0.9718 - val_loss: 0.0701 - val_accuracy: 0.9810\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0567 - accuracy: 0.9842\n",
      "Train error: 2.82%\n",
      "Test error: 1.58%\n",
      "Duration: 488.70 seconds\n"
     ]
    }
   ],
   "source": [
    "conf8=Sequential()\n",
    " \n",
    "conf8.add(Conv2D(filters=128, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf8.add(BatchNormalization())\n",
    "conf8.add(Conv2D(filters=128, kernel_size = (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf8.add(BatchNormalization())\n",
    "    \n",
    "conf8.add(Flatten())\n",
    "conf8.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf8.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf8.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf8.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf8\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a29fce52-a598-401e-b862-a7bd53cf930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 25s 29ms/step - loss: 1.1364 - accuracy: 0.6726 - val_loss: 1.7856 - val_accuracy: 0.5093\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 23s 27ms/step - loss: 0.8952 - accuracy: 0.7235 - val_loss: 6.1027 - val_accuracy: 0.2572\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 24s 29ms/step - loss: 0.8588 - accuracy: 0.7346 - val_loss: 6.9699 - val_accuracy: 0.2103\n",
      "Epoch 4/5\n",
      "843/844 [============================>.] - ETA: 0s - loss: 0.8312 - accuracy: 0.7469Restoring model weights from the end of the best epoch: 1.\n",
      "844/844 [==============================] - 21s 25ms/step - loss: 0.8310 - accuracy: 0.7470 - val_loss: 8.6637 - val_accuracy: 0.1743\n",
      "Epoch 4: early stopping\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6688 - accuracy: 0.5261\n",
      "Train error: 25.30%\n",
      "Test error: 47.39%\n",
      "Duration: 93.74 seconds\n"
     ]
    }
   ],
   "source": [
    "conf9=Sequential()\n",
    " \n",
    "conf9.add(Conv2D(filters=64, kernel_size = (1,1), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf9.add(BatchNormalization())\n",
    "conf9.add(Conv2D(filters=64, kernel_size = (1,1), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf9.add(BatchNormalization())\n",
    "    \n",
    "conf9.add(Flatten())\n",
    "conf9.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf9.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf9.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf9.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf9\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c35731bf-6c0e-401d-94d0-5230cf5135a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 42s 49ms/step - loss: 0.5447 - accuracy: 0.9042 - val_loss: 0.2192 - val_accuracy: 0.9607\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 42s 50ms/step - loss: 0.2084 - accuracy: 0.9599 - val_loss: 0.0891 - val_accuracy: 0.9827\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 41s 49ms/step - loss: 0.1537 - accuracy: 0.9686 - val_loss: 0.1107 - val_accuracy: 0.9775\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 42s 49ms/step - loss: 0.1150 - accuracy: 0.9744 - val_loss: 0.0977 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 46s 55ms/step - loss: 0.1062 - accuracy: 0.9751 - val_loss: 0.0648 - val_accuracy: 0.9855\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0590 - accuracy: 0.9847\n",
      "Train error: 2.49%\n",
      "Test error: 1.53%\n",
      "Duration: 214.04 seconds\n"
     ]
    }
   ],
   "source": [
    "conf10=Sequential()\n",
    " \n",
    "conf10.add(Conv2D(filters=64, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform', input_shape=(28,28,1)))\n",
    "conf10.add(BatchNormalization())\n",
    "conf10.add(Conv2D(filters=64, kernel_size = (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "conf10.add(BatchNormalization())\n",
    "    \n",
    "conf10.add(Flatten())\n",
    "conf10.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "conf10.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "start_time = time.time()\n",
    "history = conf10.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=64),\n",
    "    epochs=5,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[es])\n",
    "duration = time.time()-start_time\n",
    "\n",
    "test_loss, test_acc = conf10.evaluate(test_images, test_labels)\n",
    "test_error = 1.0 - test_acc\n",
    "\n",
    "results.append({\n",
    "    \"Configuration\": \"conf10\",\n",
    "    \"Train Error\": f\"{(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\",\n",
    "    \"Test Error\": f\"{test_error * 100:.2f}%\",\n",
    "    \"Duration(seconds)\": f\"{duration:.2f}\"\n",
    "})\n",
    "print(f\"Train error: {(1.0 - history.history['accuracy'][-1]) * 100:.2f}%\\nTest error: {test_error * 100:.2f}%\\nDuration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef45a864-ff2a-40c6-8741-c37bc8aa979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Configuration Train Error Test Error Duration(seconds)\n",
      "0          model       2.88%      1.93%            149.24\n",
      "1          conf1       2.84%      1.46%            155.76\n",
      "2          conf2       2.89%      3.94%            144.78\n",
      "3          conf3       4.00%      6.57%             95.11\n",
      "4          conf4       2.12%      1.88%            280.47\n",
      "5          conf5       2.77%      1.89%            152.13\n",
      "6          conf6       2.48%      1.87%            247.18\n",
      "7          conf7       2.83%      2.51%             79.38\n",
      "8          conf8       2.82%      1.58%            488.70\n",
      "9          conf9      25.30%     47.39%             93.74\n",
      "10        conf10       2.49%      1.53%            214.04\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22292668-d5c3-431e-a6c0-9d351d9b17f1",
   "metadata": {},
   "source": [
    "## Daftar Referensi\n",
    "1. https://paperswithcode.com/datasets?task=image-classification\n",
    "2. https://keras.io/api/datasets/mnist/\n",
    "3. https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner\n",
    "4. https://keras.io/layers/core/\n",
    "5. https://keras.io/layers/convolutional/\n",
    "6. https://keras.io/layers/pooling/\n",
    "7. https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "8. https://keras.io/api/callbacks/early_stopping/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
